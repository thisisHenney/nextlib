# foamdict/parser.py
from __future__ import annotations

from typing import List, Optional
from nextlib.openfoam.PyFoamDict4.lexer import *
from nextlib.openfoam.PyFoamDict4.cst import *



class ParseError(Exception):
    pass


class Parser:
    def __init__(self, tokens: List[Token]):
        self.tokens = tokens
        self.i = 0

    # -------------------------
    # Token helpers
    # -------------------------

    def cur(self) -> Token:
        # i가 tokens 범위를 넘어가면 항상 마지막(EOF) 토큰을 반환
        if self.i >= len(self.tokens):
            return self.tokens[-1]
        return self.tokens[self.i]

    def eat(self, kind: str | None = None, text: str | None = None) -> Token:
        t = self.cur()

        if kind is not None and t.kind != kind:
            raise ParseError(f"Expected {kind}, got {t.kind} at {t.start}")
        if text is not None and getattr(t, "text", None) != text:
            raise ParseError(f"Expected {text!r}, got {getattr(t, 'text', None)!r} at {t.start}")

        # ✅ EOF에서는 인덱스를 올리지 않는다 (여기가 핵심)
        if t.kind != "EOF":
            self.i += 1
        return t

    def skip_comments(self):
        while True:
            t = self.cur()
            if t.kind == "COMMENT":
                # eat()가 EOF에서 멈추므로 안전
                self.eat("COMMENT")
                continue
            break

    def make_token_node(self, t):
        return CSTToken(
            span=Span(t.start.index, t.end.index),  # ✅
            text=t.text
        )

    # -------------------------
    # Entry point
    # -------------------------
    def parse(self) -> CSTDict:
        self.skip_comments()
        start = self.cur().start.index
        entries: List[CSTEntry] = []

        # 1) header/normal dict entries
        while self.cur().kind in ("WORD", "DIRECTIVE"):
            self.skip_comments()
            if self.cur().kind not in ("WORD", "DIRECTIVE"):
                break
            entries.append(self.parse_entry())
            self.skip_comments()

        # 2) polyMesh-style trailing: NUMBER ( ... )
        self.skip_comments()

        # ⭐ lookahead: NUMBER 다음이 "(" 인 경우만 polyMesh
        if (
                self.cur().kind == "NUMBER"
                and self.i + 1 < len(self.tokens)
                and self.tokens[self.i + 1].kind == "PUNCT"
                and self.tokens[self.i + 1].text == "("
        ):
            count_tok = self.make_token_node(self.eat("NUMBER"))
            self.skip_comments()

            lst = self.parse_list()

            fake_key = CSTToken(span=count_tok.span, text=count_tok.text)
            entries.append(
                CSTEntry(
                    span=Span(count_tok.span.start, lst.span.end),
                    key_token=fake_key,
                    value_node=lst
                )
            )

        end = self.cur().end.index
        return CSTDict(span=Span(start, end), entries=entries)


    # -------------------------
    # Grammar
    # -------------------------
    def parse_entry(self) -> CSTEntry:
        self.skip_comments()
        t = self.cur()

        # key는 WORD / DIRECTIVE / STRING 허용
        if t.kind not in ("WORD", "DIRECTIVE", "STRING"):
            raise ParseError(f"Expected key, got {t.kind} at {t.start}")

        key_tok = self.eat()
        key_node = self.make_token_node(key_tok)

        # STRING key면 따옴표 포함 텍스트 그대로(lexer에서 이미 처리된 값 기준)
        if key_tok.kind == "STRING":
            key_node.text = key_tok.text

        self.skip_comments()
        value_node = self.parse_value()

        # parse_value가 절대 None을 반환하면 안 됨 (방어)
        if value_node is None:
            pos = self.cur().start.index
            value_node = CSTEmpty(span=Span(pos, pos))

        # entry 종료 세미콜론은 여기서 소비
        semi = None
        self.skip_comments()
        if self.cur().kind == "PUNCT" and self.cur().text == ";":
            semi = self.make_token_node(self.eat("PUNCT", ";"))

        return CSTEntry(
            span=Span(key_node.span.start, value_node.span.end),
            key_token=key_node,
            value_node=value_node,
            semi_token=semi
        )

    def parse_value(self) -> CSTNode:
        self.skip_comments()
        t = self.cur()

        # dict / list 는 그대로
        if t.kind == "PUNCT" and t.text == "{":
            return self.parse_dict_block()
        if t.kind == "PUNCT" and t.text == "(":
            return self.parse_list()

        # value가 비어있는 경우
        if t.kind == "EOF" or (t.kind == "PUNCT" and t.text in (";", "}", ")")):
            pos = t.start.index
            return CSTEmpty(span=Span(pos, pos))

        # ✅ 여기부터는 "세미콜론/닫힘" 전까지 전부 수집
        parts: list[CSTNode] = []
        start = t.start.index

        while True:
            self.skip_comments()
            t = self.cur()

            if t.kind == "EOF":
                break
            if t.kind == "PUNCT" and t.text in (";", "}", ")"):
                break

            # 중첩 구조도 value의 일부로 포함
            if t.kind == "PUNCT" and t.text == "{":
                parts.append(self.parse_dict_block())
                continue
            if t.kind == "PUNCT" and t.text == "(":
                parts.append(self.parse_list())
                continue

            parts.append(self.make_token_node(self.eat()))

        if not parts:
            return CSTEmpty(span=Span(start, start))

        if len(parts) == 1:
            return parts[0]

        return CSTSeq(span=Span(start, parts[-1].span.end), parts=parts)

    def parse_dict_block(self) -> CSTDict:
        lbrace = self.eat("PUNCT", "{")
        lnode = self.make_token_node(lbrace)

        entries = []

        while True:
            self.skip_comments()
            t = self.cur()

            if t.kind == "PUNCT" and t.text == "}":
                break
            if t.kind == "EOF":
                break

            # dict 내부는 entry만 허용 (세미콜론은 parse_entry가 처리)
            if t.kind in ("WORD", "DIRECTIVE", "STRING"):
                entries.append(self.parse_entry())
                continue

            raise ParseError(f"Expected key, got {t.kind} at {t.start}")

        rbrace = None
        if self.cur().kind == "PUNCT" and self.cur().text == "}":
            rbrace = self.make_token_node(self.eat("PUNCT", "}"))

        return CSTDict(
            span=Span(lbrace.start.index, (rbrace.span.end if rbrace else lbrace.end.index)),
            lbrace=lnode,
            entries=entries,
            rbrace=rbrace
        )

    def parse_list(self) -> CSTList:
        lparen = self.eat("PUNCT", "(")
        items = []

        while True:
            self.skip_comments()
            t = self.cur()

            if t.kind == "EOF":
                raise ParseError(f"Unterminated list '(' at {lparen.start}")

            if t.kind == "PUNCT" and t.text == ")":
                break

            # ⭐ 중첩 리스트
            if t.kind == "PUNCT" and t.text == "(":
                items.append(self.parse_list())
                continue

            # dict
            if t.kind == "PUNCT" and t.text == "{":
                items.append(self.parse_dict_block())
                continue

            # scalar / string
            if t.kind in ("WORD", "NUMBER", "STRING"):
                items.append(self.make_token_node(self.eat()))
                continue

            # 세미콜론은 무시
            if t.kind == "PUNCT" and t.text == ";":
                self.eat()
                continue

            raise ParseError(f"Unexpected token in list: {t.kind} at {t.start}")

        rparen = self.eat("PUNCT", ")")
        return CSTList(
            span=Span(lparen.start.index, rparen.end.index),
            lparen=self.make_token_node(lparen),
            items=items,
            rparen=self.make_token_node(rparen)
        )


# -------------------------
# Public API
# -------------------------

def parse_cst(text: str) -> CSTDict:
    tokens = lex(text)
    return Parser(tokens).parse()
